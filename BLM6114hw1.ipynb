{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyNvpYG7boLWIddvMEbbfTsg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyupdalan/BLM6114-hw1/blob/main/BLM6114hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install opencv-python\n",
        "#!pip install datasets"
      ],
      "metadata": {
        "id": "TGhfr5Z86Y4C"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gmE3YpUKfVvp"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verilerin alınması\n",
        "https://huggingface.co/datasets/ytu-ce-cosmos/gsm8k_tr adresinde\n",
        "bulunan dosyadaki question ları soru, answer ları cevap olarak kullanınız.\n",
        "Bu dosyadan rasgele 1000 soru ve o sorunun cevabı 2’lisi seçiniz."
      ],
      "metadata": {
        "id": "2bFzvVpvfnHn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CSV'den okuma"
      ],
      "metadata": {
        "id": "IwiPCxsHfsd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = load_dataset(\"ytu-ce-cosmos/gsm8k_tr\")\n",
        "#all_data = dataset.to_pandas()\n",
        "\n",
        "file_path = \"/content/sample_data/gsm8k_tr.csv\"\n",
        "all_data = pd.read_csv(file_path)\n",
        "\n",
        "print(all_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdQxaTYdfxEX",
        "outputId": "ed181a02-1b1a-4698-9bc3-3265d0d484a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            question  \\\n",
            "0  Borris tekel bayisi her 6 ayda bir 90 kilogram...   \n",
            "1  Mel, Katherine'den üç yaş küçük.  Katherine ik...   \n",
            "2  James 2 ağacındaki tüm meyveleri toplar.  Her ...   \n",
            "3  Kyle, her biri 15 origami yıldızı alabilen 2 c...   \n",
            "4  Mark'ın iki evcil hayvanı var: Saniyede 10 adı...   \n",
            "\n",
            "                                              answer  \n",
            "0  Borris şu anda her 6 ayda 90 kilogram üzüm kul...  \n",
            "1  Katherine iki düzine yaşına geldiğinde 24 yaşı...  \n",
            "2                           James 24 ağaç dikmiştir.  \n",
            "3  Kyle toplamda 5 cam şişe satın aldı (2 + 3). H...  \n",
            "4  Kaplumbağanın yarışı berabere bitirmesi için 1...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rasgele 1000 datanın alınması"
      ],
      "metadata": {
        "id": "mUPR9NAlgqAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_count = 1000 #1000\n",
        "total_data_length = len(all_data)\n",
        "print(\"Total data length: \", total_data_length)\n",
        "\n",
        "random.seed(111)\n",
        "randomly_selected_indices = random.sample(range(total_data_length), sample_count) #randomly select 1000 samples\n",
        "\n",
        "data = all_data.iloc[randomly_selected_indices].reset_index(drop=True)\n",
        "\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHzO4eRRgt78",
        "outputId": "814f3ac5-10c7-4501-e65f-8689a946489f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total data length:  8792\n",
            "                                            question  \\\n",
            "0  Bayan Thompson tanesi 3 dolardan 3 tavuk aldı....   \n",
            "1  Bir bekleme odasında yirmi iki kişi bulunmakta...   \n",
            "2  Elise babasının 250 kitaptan oluşan koleksiyon...   \n",
            "3  Beyaz tavşan bir dakikada 15 metre zıplayabili...   \n",
            "4  Grubun konserine 500 kişi katıldı. Bu konser i...   \n",
            "\n",
            "                                              answer  \n",
            "0                      Patatesler 6 dolara mal oldu.  \n",
            "1                 Görüşme odasında dört kişi vardır.  \n",
            "2  Elise'nin babasının 250 kitaplık koleksiyonund...  \n",
            "3  Beyaz tavşanın 5 dakikada zıplayacağı mesafe: ...  \n",
            "4  Her bilet 30$ ve grup bilet fiyatının %70'ini ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Seçilen modeller\n",
        "https://huggingface.co/spaces/mteb/leaderboard adresinde ilk 100’e girmiş, multilingual olan ve 1 milyar parametreden küçük olan 5 model"
      ],
      "metadata": {
        "id": "nreTNV_Pg1q7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenizer işlemleri"
      ],
      "metadata": {
        "id": "Twg6hqkTg9kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_models = [\n",
        "    \"intfloat/multilingual-e5-large-instruct\",\n",
        "]\n",
        "compare_model = \"ytu-ce-cosmos/turkish-colbert\"\n",
        "all_models = selected_models + [compare_model]\n",
        "\n",
        "print(\"All models: \", all_models)\n",
        "\n",
        "def average_pool(last_hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "def create_model_embeddings(model_name, input_text, batch_size=32):\n",
        "    embeddings_list = []\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "    # Tek seferde embedding hesaplaması çok fazla memory tüketimine sebep olup\n",
        "    # crash olmasına sebep oluyordu. o yüzden burada batch_size'a göre parçalı\n",
        "    # parçalı hesaplanması sağlandı\n",
        "    for i in range(0, len(input_text), batch_size):\n",
        "        batch = input_text[i : i + batch_size]\n",
        "        with torch.no_grad():\n",
        "            batch_dict = tokenizer(batch, max_length=128, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "            batch_dict = {k: v.to(model.device) for k, v in batch_dict.items()}\n",
        "            outputs = model(**batch_dict)\n",
        "        embeddings = average_pool(outputs.last_hidden_state, batch_dict[\"attention_mask\"])\n",
        "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "        embeddings_list.append(embeddings)\n",
        "\n",
        "    # Tüm embedding'leri birleştir\n",
        "    return torch.cat(embeddings_list, dim=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUbZOlAWg5Sy",
        "outputId": "489017a7-8996-4dd1-e4bb-ef3230278a7d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All models:  ['intfloat/multilingual-e5-large-instruct', 'ytu-ce-cosmos/turkish-colbert']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128  # Her batch'te işlenecek metin sayısı\n",
        "\n",
        "questions_text = data['question'].tolist()\n",
        "answers_text = data['answer'].tolist()\n",
        "\n",
        "model_embeddings_list = {}\n",
        "\n",
        "for model_name in all_models:\n",
        "    print(f\"Model: {model_name}\")\n",
        "\n",
        "    question_embeddings = create_model_embeddings(model_name, questions_text, batch_size=batch_size)\n",
        "    answer_embeddings = create_model_embeddings(model_name, answers_text, batch_size=batch_size)\n",
        "\n",
        "    model_embeddings_list[model_name] = {\n",
        "        \"questions\": question_embeddings,\n",
        "        \"answers\": answer_embeddings\n",
        "    }\n",
        "    print(f\"{model_name} embedding created\")\n",
        "\n",
        "print(\"All embeddings created\", model_embeddings_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hcaY6UglhAVT",
        "outputId": "22296155-f2e0-4dd2-e06b-6ca8ab7b0182"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: intfloat/multilingual-e5-large-instruct\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "intfloat/multilingual-e5-large-instruct embedding created\n",
            "Model: ytu-ce-cosmos/turkish-colbert\n",
            "ytu-ce-cosmos/turkish-colbert embedding created\n",
            "All embeddings created {'intfloat/multilingual-e5-large-instruct': {'questions': tensor([[ 0.0209,  0.0050, -0.0376,  ..., -0.0453, -0.0612,  0.0097],\n",
            "        [ 0.0171,  0.0103, -0.0421,  ..., -0.0458, -0.0338,  0.0402],\n",
            "        [ 0.0060,  0.0083, -0.0304,  ..., -0.0306, -0.0517,  0.0340],\n",
            "        ...,\n",
            "        [ 0.0230,  0.0041, -0.0480,  ..., -0.0193, -0.0522,  0.0265],\n",
            "        [ 0.0069,  0.0024, -0.0320,  ..., -0.0592, -0.0515,  0.0153],\n",
            "        [-0.0060,  0.0166, -0.0378,  ..., -0.0472, -0.0371,  0.0280]]), 'answers': tensor([[ 0.0208,  0.0143,  0.0043,  ..., -0.0237, -0.0274,  0.0255],\n",
            "        [ 0.0321,  0.0276, -0.0135,  ..., -0.0354, -0.0332,  0.0268],\n",
            "        [ 0.0321,  0.0085, -0.0171,  ..., -0.0303, -0.0581,  0.0394],\n",
            "        ...,\n",
            "        [-0.0066,  0.0149, -0.0326,  ..., -0.0219, -0.0482,  0.0353],\n",
            "        [ 0.0032, -0.0170, -0.0224,  ..., -0.0149, -0.0478,  0.0076],\n",
            "        [ 0.0061,  0.0196, -0.0278,  ..., -0.0356, -0.0327,  0.0378]])}, 'ytu-ce-cosmos/turkish-colbert': {'questions': tensor([[ 0.0645,  0.0328,  0.0138,  ...,  0.0502, -0.0798,  0.0352],\n",
            "        [ 0.0046,  0.0486,  0.0088,  ...,  0.0305,  0.0164,  0.0367],\n",
            "        [ 0.0567,  0.0554,  0.0183,  ...,  0.0538, -0.0501,  0.0551],\n",
            "        ...,\n",
            "        [ 0.0082,  0.0134,  0.0214,  ...,  0.0580, -0.0736,  0.0391],\n",
            "        [ 0.0621,  0.0543,  0.0289,  ...,  0.0450, -0.0403,  0.0484],\n",
            "        [-0.0013, -0.0182, -0.0111,  ...,  0.0513, -0.0555,  0.0244]]), 'answers': tensor([[ 0.0095,  0.0122,  0.0095,  ...,  0.0693, -0.0702,  0.0471],\n",
            "        [ 0.0013,  0.0586,  0.0237,  ...,  0.0229, -0.0088,  0.0412],\n",
            "        [ 0.0629,  0.0311,  0.0137,  ...,  0.0658, -0.0698,  0.0553],\n",
            "        ...,\n",
            "        [ 0.0157,  0.0046,  0.0232,  ...,  0.0309, -0.0733,  0.0592],\n",
            "        [ 0.0483,  0.0305,  0.0189,  ...,  0.0716, -0.0356,  0.0199],\n",
            "        [-0.0064, -0.0221, -0.0047,  ...,  0.0505, -0.0545,  0.0392]])}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Arama ve top1 top5 baraşarılarını hesaplama fonksiyonları"
      ],
      "metadata": {
        "id": "YrnQRBeEnrB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_most_similar_answer_indices(embeddings: torch.Tensor, query_idx: int, top_k: int = 5):\n",
        "    query = embeddings[\"questions\"][query_idx].unsqueeze(0)\n",
        "    similarity = F.cosine_similarity(query, embeddings[\"answers\"], dim=1)\n",
        "\n",
        "    top_k_values, top_k_indices = torch.topk(similarity, top_k)\n",
        "    # Tensor'ları Python listesine dönüştür\n",
        "    top_k_indices = top_k_indices.tolist()\n",
        "\n",
        "    # Sadece top_k sonucu al\n",
        "    top_k_scores = [similarity[idx].item() for idx in top_k_indices]\n",
        "\n",
        "    return top_k_indices, top_k_scores\n",
        "\n",
        "def search_from_answer_embedding(embeddings: torch.Tensor, query_idx: int, top_k: int = 5):\n",
        "    top_k_indices, top_k_scores = find_most_similar_answer_indices(embeddings, query_idx, top_k)\n",
        "    top_k_results = [answers_text[idx] for idx in top_k_indices]\n",
        "\n",
        "    #print(f\"Sorgu: {answers_text[query_idx]}\")\n",
        "    #for i, (result, score) in enumerate(zip(top_k_results, top_k_scores)):\n",
        "    #    print(f\"{i+1}. Benzerlik: {score:.4f}, Metin: {result}\")\n",
        "\n",
        "    return top_k_results, top_k_scores, top_k_indices\n",
        "\n",
        "def calculate_answers_accuracy(embeddings: torch.Tensor, top_k: int = 5):\n",
        "    total_correct = 0\n",
        "    total_queries = len(embeddings[\"answers\"])\n",
        "\n",
        "    for query_idx in range(total_queries):\n",
        "        top_k_results, top_k_scores, top_k_indices = search_from_answer_embedding(embeddings, query_idx, top_k)\n",
        "\n",
        "        # sorunun index'i ile doğru cevabının index'i aynı\n",
        "        if(query_idx in top_k_indices):\n",
        "            total_correct += 1\n",
        "\n",
        "    accuracy = total_correct / total_queries\n",
        "    return accuracy\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "cx4doM3_oBCE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Örnek soru top-5 sonuçları"
      ],
      "metadata": {
        "id": "FRoKMybRVYFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in all_models:\n",
        "  embeddings = model_embeddings_list[model_name]\n",
        "  accuracy = calculate_answers_accuracy(embeddings, 5)\n",
        "  print(f\"Model: {model_name}, accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i34KdR4PUOID",
        "outputId": "c233932a-bdfb-46b4-f99c-8ef3686f523a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: intfloat/multilingual-e5-large-instruct, accuracy: 0.899\n",
            "Model: ytu-ce-cosmos/turkish-colbert, accuracy: 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMUaq4YlYtgi",
        "outputId": "ed1fad08-fede-4f4e-c0ce-d5a87e56ea1c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        }
      ]
    }
  ]
}